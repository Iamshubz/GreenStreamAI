# Pathway Integration Architecture & Implementation Details

## System Architecture Diagram

```
┌──────────────────────────────────────────────────────────────────┐
│                         GREENSTREAM AI                            │
│              Environmental Monitoring System                      │
└──────────────────────────────────────────────────────────────────┘

                    ┌─────────────────────────┐
                    │   FastAPI Web Server    │
                    │    (Port 8000)          │
                    └────────────┬────────────┘
                                 │
        ┌────────────────────────┼────────────────────────┐
        │                        │                        │
        ▼                        ▼                        ▼
   ┌─────────────┐        ┌──────────────┐       ┌────────────────┐
   │  HTTP Routes│        │ Middleware   │       │  CORS Config   │
   │  (REST API) │        │  (Logging)   │       │  (All Origins) │
   └─────────────┘        └──────────────┘       └────────────────┘
        │
        │ Uses
        ▼
   ┌─────────────────────────────────────────────────────────────┐
   │            PATHWAY PIPELINE ORCHESTRATOR                    │
   │         (pathway_pipeline.py: PathwayPipeline)              │
   │                                                             │
   │  ┌─────────────────────────────────────────────────────┐   │
   │  │  Thread-Safe Shared State                           │   │
   │  │  • latest_readings (per city)                       │   │
   │  │  • critical_alerts (buffer)                         │   │
   │  │  • rolling_averages (per city)                      │   │
   │  │  • environmental_reports (from LLM)                 │   │
   │  │  • pipeline_status (running/stopped)                │   │
   │  └─────────────────────────────────────────────────────┘   │
   └──────────────┬──────────────────────────────────────────────┘
                  │
    ┌─────────────┴──────────────┬──────────────────┐
    │                            │                  │
    ▼                            ▼                  ▼
┌──────────────────┐  ┌──────────────────┐  ┌─────────────────┐
│ INGESTION LAYER  │  │TRANSFORMATION     │  │  LLM LAYER      │
│                  │  │  LAYER            │  │                 │
│ pathway_ingestion│  │pathway_transf..  │  │ pathway_llm.py  │
│     .py          │  │     .py           │  │                 │
│                  │  │                   │  │                 │
│ ┌──────────────┐ │  │ ┌───────────────┐ │  │ ┌─────────────┐ │
│ │ Data Source  │ │  │ │ Anomaly       │ │  │ │ Document    │ │
│ │ Generator    │ │  │ │ Detection     │ │  │ │ Store       │ │
│ │              │ │  │ │               │ │  │ │             │ │
│ │ • Cities     │ │  │ │ • AQI > 200   │ │  │ │ • Reports   │ │
│ │ • Temp       │ │  │ │ • CO2 > 600   │ │  │ │ • Expl.     │ │
│ │ • AQI        │ │  │ │               │ │  │ │ • Rec.      │ │
│ │ • CO2        │ │  │ │ Rolling Avg   │ │  │ │             │ │
│ │ • Humidity   │ │  │ │ (Per City)    │ │  │ │ Google      │ │
│ │              │ │  │ │               │ │  │ │ Gemini API  │ │
│ │ 500ms/read   │ │  │ │ Alert Filter  │ │  │ │             │ │
│ └──────────────┘ │  │ └───────────────┘ │  │ └─────────────┘ │
└──────────────────┘  └───────────────────┘  └─────────────────┘
```

## Component Details

### 1. Ingestion Layer

```python
# pathway_ingestion.py

┌────────────────────────────────────┐
│  EnvironmentalDataSchema           │
├────────────────────────────────────┤
│  • city: str                       │
│  • aqi: int                        │
│  • co2: int                        │
│  • temperature: float              │
│  • humidity: int                   │
│  • timestamp: str                  │
└────────────────────────────────────┘
        │
        │ Generated by
        ▼
┌──────────────────────────────────────────────┐
│ generate_environmental_data()                 │
├──────────────────────────────────────────────┤
│ • Simulates 4 cities                         │
│ • Realistic AQI ranges per city              │
│ • Random but bounded values                  │
│ • Yields every 500ms                         │
└──────────────────────────────────────────────┘
        │
        │ Wrapped by
        ▼
┌──────────────────────────────────────────────┐
│ PathwayIngestionLayer                        │
├──────────────────────────────────────────────┤
│ • create_data_source()                       │
│   └─> Returns pw.Table                       │
│ • Streaming mode enabled                     │
└──────────────────────────────────────────────┘
```

### 2. Transformation Layer

```python
# pathway_transformations.py

Input Table (Raw Data)
        │
        ├─────────────────────┬──────────────────┐
        │                     │                  │
        ▼                     ▼                  ▼
    ┌────────────┐      ┌─────────────┐    ┌──────────────┐
    │ Classify   │      │ Filter      │    │ Aggregate    │
    │ Anomalies  │      │ Criticals   │    │ Per City     │
    │            │      │             │    │              │
    │ is_aqi_c   │      │ AQI > 200   │    │ avg_aqi      │
    │ is_co2_h   │      │ CO2 > 600   │    │ avg_co2      │
    │ is_aqi_w   │      │             │    │ avg_temp     │
    │ is_co2_w   │      │ Severity:   │    │ avg_humidity │
    │            │      │ critical    │    │              │
    └────────────┘      └─────────────┘    └──────────────┘
        │                     │                  │
        └─────────────────────┼──────────────────┘
                              │
                    ┌─────────▼──────────┐
                    │ Output Tables      │
                    ├────────────────────┤
                    │ • critical_alerts  │
                    │ • rolling_averages │
                    │ • classified_data  │
                    └────────────────────┘

Thresholds:
  Critical:  AQI > 200 ║ CO2 > 600
  Warning:   AQI > 150 ║ CO2 > 500
```

### 3. LLM Layer

```python
# pathway_llm.py

Alert Event
    │
    ▼
┌──────────────────────────────────┐
│ PathwayLLMLayer                  │
├──────────────────────────────────┤
│                                  │
│  generate_explanation()          │
│  ├─> Prompt: AQI + CO2 + City    │
│  └─> Response: 2-3 sentences     │
│                                  │
│  generate_recommendation()       │
│  ├─> Prompt: Alert type + Values │
│  └─> Response: Action items      │
│                                  │
│  store_report()                  │
│  ├─> Create EnvironmentalReport  │
│  └─> Add to document_store       │
│                                  │
└──────────────────────────────────┘
        │
        ▼
┌──────────────────────────────────┐
│ Document Store (In-Memory Cache) │
├──────────────────────────────────┤
│ • Last 100 reports               │
│ • Keyed by report_id             │
│ • Query by city                  │
│ • Stats tracking                 │
└──────────────────────────────────┘
        │
        ▼
┌──────────────────────────────────┐
│ EnvironmentalReport              │
├──────────────────────────────────┤
│ • city                           │
│ • aqi, co2, temp, humidity       │
│ • alert_type                     │
│ • severity                       │
│ • explanation (LLM)              │
│ • recommendation (LLM)           │
│ • timestamp                      │
└──────────────────────────────────┘
```

### 4. Pipeline Orchestrator

```python
# pathway_pipeline.py

┌──────────────────────────────────────────┐
│ PathwayPipeline (Singleton)              │
├──────────────────────────────────────────┤
│                                          │
│  ┌──────────────────────────────────┐   │
│  │ __init__()                       │   │
│  │ • Create ingestion layer         │   │
│  │ • Create transformation layer    │   │
│  │ • Create LLM layer               │   │
│  │ • Initialize shared state        │   │
│  │ • Setup data buffers             │   │
│  └──────────────────────────────────┘   │
│                                          │
│  ┌──────────────────────────────────┐   │
│  │ run() [in background thread]     │   │
│  │ • Initialize components          │   │
│  │ • Process streaming data         │   │
│  │ • Update shared state            │   │
│  │ • Run continuously               │   │
│  └──────────────────────────────────┘   │
│                                          │
│  ┌──────────────────────────────────┐   │
│  │ Public APIs                      │   │
│  │ • get_state()                    │   │
│  │ • get_critical_alerts()          │   │
│  │ • get_rolling_averages()         │   │
│  │ • get_environmental_reports()    │   │
│  └──────────────────────────────────┘   │
│                                          │
└──────────────────────────────────────────┘
        │
        │ Manages
        ▼
┌──────────────────────────────────────────┐
│ Shared State (Thread-Protected)          │
├──────────────────────────────────────────┤
│                                          │
│ latest_readings                          │
│  └─ {city: {aqi, co2, temp, hum, ts}}   │
│                                          │
│ critical_alerts                          │
│  └─ [{city, aqi, co2, alert_type, ...}] │
│                                          │
│ rolling_averages                         │
│  └─ {city: {avg_aqi, avg_co2, ...}}     │
│                                          │
│ environmental_reports                    │
│  └─ [{city, explanation, rec, ...}]     │
│                                          │
│ is_running / last_update                │
│                                          │
└──────────────────────────────────────────┘
```

## Data Flow Through Pipeline

```
Time: t=0ms
└─ Ingestion: Generate {Delhi, AQI=245, CO2=650, ...}

Time: t=1ms
├─ Transformation: AQI > 200? YES → ALERT
├─ Transformation: CO2 > 600? YES → ALERT
└─ Create: AnomalyAlert record

Time: t=5ms
├─ Update latest_readings[Delhi] = {...}
└─ Add to critical_alerts buffer

Time: t=10ms
├─ Compute rolling average for Delhi
└─ Update rolling_averages[Delhi] = {avg_aqi: 220, ...}

Time: t=100ms
├─ LLM Layer triggered for new alert
├─ Generate explanation (1-3 sec API call)
└─ Generate recommendation (1-3 sec API call)

Time: t=3100ms
├─ LLM completed
├─ Store report in document_store
└─ Add to environmental_reports buffer
```

## API Request-Response Flow

```
Client Request
    │
    ▼
GET /api/alerts
    │
    ▼
┌─────────────────────────────────┐
│ api.get_alerts()                │
├─────────────────────────────────┤
│ 1. pipeline = get_pipeline()    │
│ 2. alerts = pipeline.get_...()  │
│ 3. Convert to Pydantic models   │
│ 4. Return JSON                  │
└─────────────────────────────────┘
    │
    ▼
┌─────────────────────────────────┐
│ Pathway Pipeline (background)   │
├─────────────────────────────────┤
│ • Thread-safe state access      │
│ • Acquire lock                  │
│ • Return snapshot               │
│ • Release lock                  │
└─────────────────────────────────┘
    │
    ▼
HTTP 200 OK
[
  {
    "city": "Delhi",
    "aqi": 245,
    "co2": 650,
    "alert_type": "aqi_critical",
    "severity": "critical",
    ...
  }
]
```

## Anomaly Detection Logic

```python
def detect_anomaly(aqi: int, co2: int) -> (str, str):
    """
    Returns: (alert_type, severity)
    """
    
    # Priority: Critical > Warning
    
    if aqi > 200 and co2 > 600:
        return ("aqi_critical+co2_high", "critical")
    
    if aqi > 200:
        return ("aqi_critical", "critical")
    
    if co2 > 600:
        return ("co2_high", "critical")
    
    if aqi > 150 or co2 > 500:
        return ("warning", "warning")
    
    return (None, None)  # No anomaly

Thresholds Table:
┌──────┬────────┬─────────┐
│Level │  AQI   │  CO2    │
├──────┼────────┼─────────┤
│Crit. │ > 200  │ > 600   │
│Warn. │ > 150  │ > 500   │
│Good  │ ≤ 150  │ ≤ 500   │
└──────┴────────┴─────────┘

Typical AQI Ranges (Demo):
  Delhi:     120-350 (high)
  Mumbai:    80-250  (medium)
  Bangalore: 50-200  (low-medium)
  Chennai:   40-180  (low)
```

## State Management & Thread Safety

```python
# Shared State Access Pattern

pipeline_lock = Lock()

def update_state(key, value):
    with pipeline_lock:
        state[key] = value

def read_state():
    with pipeline_lock:
        return copy.deepcopy(state)

# Benefits:
# ✓ No race conditions
# ✓ Consistent snapshots for API
# ✓ Background thread safe
# ✓ Fast read/write operations
```

## Error Handling & Fallbacks

```
Scenario: LLM API Unavailable
  │
  ├─> generate_explanation() fails
  │     └─> Return get_fallback_explanation()
  │
  ├─> generate_recommendation() fails
  │     └─> Return get_fallback_recommendation()
  │
  └─> Report still created with fallback text
      (LLM not required for core functionality)

Scenario: Invalid Data Point
  │
  └─> try-except in _update_state_with_data()
      └─> Log error, continue processing

Scenario: Pipeline Crash
  │
  └─> daemon=True in threading
      └─> Server continues, manually restart pipeline
```

## Performance Optimization

| Operation | Time | Method |
|-----------|------|--------|
| Anomaly Detection | <1ms | In-memory filtering |
| State Update | ~1ms | Lock-protected dict |
| Rolling Average | ~5ms | In-memory computation |
| API Response | <100ms | Cached state + JSON |
| LLM Call | 1-3s | Async in separate thread |

## Scaling Strategy

### Phase 1 (Current)
- Single instance in-memory
- Demo data only
- Suitable for: POC, development

### Phase 2 (Production)
- Database persistence
- Real data APIs
- Multiple replicas
- Load balancer

### Phase 3 (Enterprise)
- Distributed Pathway
- Kafka/Stream processor
- Microservices
- Global deployment

---

## Implementation Notes

1. **Why Singleton Pattern?**
   - Ensures single pipeline instance
   - Global access without circular imports
   - Thread-safe initialization

2. **Why In-Memory State?**
   - Low latency (<100ms API response)
   - Simple for demo/POC
   - Easy migration to DB later

3. **Why Thread-Safe Lock?**
   - Background thread updates state continuously
   - API threads read state concurrently
   - Prevents inconsistent reads

4. **Why Async LLM?**
   - LLM calls are slow (1-3 sec)
   - Store report asynchronously
   - Don't block pipeline data processing

5. **Why Document Store?**
   - Maintains history of reports
   - Enables analytics/dashboards
   - Quick access without re-running LLM

---

**Architecture Version:** 1.0  
**Last Updated:** March 2026
